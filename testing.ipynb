{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 80.0\n",
      "Layerindex: 0\n",
      "Total number of layers: 10\n",
      "Layer: 81.0\n",
      "Layerindex: 1\n",
      "Total number of layers: 10\n",
      "Layer: 82.0\n",
      "Layerindex: 2\n",
      "Total number of layers: 10\n",
      "Layer: 83.0\n",
      "Layerindex: 3\n",
      "Total number of layers: 10\n",
      "Layer: 130.0\n",
      "Layerindex: 4\n",
      "Total number of layers: 10\n",
      "Layer: 131.0\n",
      "Layerindex: 5\n",
      "Total number of layers: 10\n",
      "Layer: 132.0\n",
      "Layerindex: 6\n",
      "Total number of layers: 10\n",
      "Layer: 133.0\n",
      "Layerindex: 7\n",
      "Total number of layers: 10\n",
      "Layer: 170.0\n",
      "Layerindex: 8\n",
      "Total number of layers: 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "evt = \"/mnt/data0/Trackml_dataset_100_events/Example_3/trackml_100_events/event000021000-\"\n",
    "\n",
    "#cells = pd.read_csv(evt+'cells.csv')\n",
    "hits = pd.read_csv(evt+'hits.csv')\n",
    "#particles = pd.read_csv(evt+'particles.csv')\n",
    "#truth = pd.read_csv(evt+'truth.csv')\n",
    "\n",
    "#print(\"Cells:\",cells.head())\n",
    "#print(\"Hits:\",hits.head())\n",
    "#print(\"Particles:\",particles.head())\n",
    "#print(\"Truth:\",truth.head())\n",
    "\n",
    "#Only keep hits with volume_id = 8,13,17\n",
    "hits = hits[hits.volume_id.isin([8,13,17])]\n",
    "\n",
    "#Relabel layer_id to contain volume information\n",
    "hits['layer_id'] = hits['layer_id']/2 - 1\n",
    "hits['layer_id'] = hits['volume_id']*10 + hits['layer_id']\n",
    "\n",
    "hits = hits.sort_values(by='layer_id')\n",
    "\n",
    "def semi_fully_connected_graph(event_path):\n",
    "    hits = pd.read_csv(event_path + 'hits.csv')\n",
    "    hits = hits[hits.volume_id.isin([8,13,17])] #only consider barrel detector\n",
    "    hits = hits[hits.y > 0] #only consider top half of detector\n",
    "\n",
    "    hits['layer_id'] = hits['layer_id']/2 - 1\n",
    "    hits['layer_id'] = hits['volume_id']*10 + hits['layer_id']\n",
    "\n",
    "    hits = hits.sort_values(by='layer_id')\n",
    "\n",
    "    edge_index = torch.empty(1,2)\n",
    "\n",
    "    for i,layer in enumerate(hits['layer_id'].unique()):\n",
    "        print(\"Layer:\",layer)\n",
    "        print(\"Layerindex:\",i)\n",
    "        print(\"Total number of layers:\",hits['layer_id'].unique().shape[0])\n",
    "\n",
    "        \"\"\"\n",
    "        Naiive approach: itertools.product contains nested for loop, not yet parallelized for every layer\n",
    "        \"\"\"\n",
    "        last = int(hits['layer_id'].unique().shape[0]) - 2\n",
    "\n",
    "        #Hits in current layer\n",
    "        layer_hits = hits[hits.layer_id == int(layer)]\n",
    "\n",
    "        #Create all combinations of hits in current layer and next layer\n",
    "        next_layer = hits['layer_id'].unique()[i+1] \n",
    "        next_layer_hits = hits[hits.layer_id == int(next_layer)]\n",
    "        combinations_next = torch.tensor(list(product(layer_hits['hit_id'],next_layer_hits['hit_id'])))\n",
    "        edge_index = torch.cat((edge_index,combinations_next),dim=0)\n",
    "\n",
    "        if i == last:\n",
    "            break\n",
    "\n",
    "        #Create all combinations of hits in current layer and nextnext layer\n",
    "        nextnext_layer = hits['layer_id'].unique()[i+2]\n",
    "        nextnext_layer_hits = hits[hits.layer_id == int(nextnext_layer)]\n",
    "        combinations_nextnext = torch.tensor(list(product(layer_hits['hit_id'],nextnext_layer_hits['hit_id'])))\n",
    "        edge_index = torch.cat((edge_index,combinations_nextnext),dim=0)\n",
    "\n",
    "    graph = Data()\n",
    "    graph.x = torch.tensor(hits['hit_id'].values)\n",
    "    graph.edge_index = edge_index\n",
    "    \n",
    "    return graph\n",
    "\n",
    "graph = semi_fully_connected_graph(evt)\n",
    "torch.save(graph,'hit_graph_small_event000021000.pyg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges before filter: 190923020\n",
      "Number of edges after filter: 19093\n",
      "Total number of nodes: 33590\n",
      "Number of connected nodes: 22258\n",
      "Data(x=[22258], edge_index=[19093, 2])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "graph = torch.load('hit_graph_small_event000021000.pyg')\n",
    "\n",
    "#Random filter to remove edges and unconnected nodes\n",
    "def random_filter(graph, p=0.9999):\n",
    "    print('Number of edges before filter:',graph.edge_index.shape[0])\n",
    "    remove_edges = random.sample(range(0,graph.edge_index.shape[0]),int(graph.edge_index.shape[0]*p))\n",
    "    graph.edge_index = torch.from_numpy(np.delete(graph.edge_index.numpy(),remove_edges,axis=0))\n",
    "    print('Number of edges after filter:',graph.edge_index.shape[0])\n",
    "    graph = delete_unconnected_nodes(graph)\n",
    "    return graph\n",
    "\n",
    "def delete_unconnected_nodes(graph):\n",
    "    print('Total number of nodes:',graph.x.shape[0])\n",
    "    print('Number of connected nodes:',np.unique(graph.edge_index.numpy()).shape[0])\n",
    "    graph.x = torch.tensor(np.unique(graph.edge_index.numpy()))\n",
    "    return graph\n",
    "\n",
    "graph = random_filter(graph)\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linegraph(graph):\n",
    "    \n",
    "\n",
    "    new_graph = Data()\n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3]\n",
      " [4 5 6 7 4 5 6 7 4 5 6 7 4 5 6 7]]\n"
     ]
    }
   ],
   "source": [
    "A = [0,1,2,3]\n",
    "B = [4,5,6,7]\n",
    "\n",
    "combinations = np.array(list(product(A,B))).T\n",
    "print(combinations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmicgnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
